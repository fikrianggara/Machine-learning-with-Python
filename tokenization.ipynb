{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\"\"\"\r\n",
    "cara komputer memahami kata tidak sama dengan cara komputer memahami gambar, kita perlu mengubah kata menjadi format yang bisa diproses oleh komputer\r\n",
    "caranya ialah dengan mengubah kata/kalimat menjadi bilangan bilangan.\r\n",
    "proses mengubah kata menjadi bilangan bilangan disebut sebagai tokenization\r\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\ncara komputer memahami kata tidak sama dengan cara komputer memahami gambar, kita perlu mengubah kata menjadi format yang bisa diproses oleh komputer\\ncaranya ialah dengan mengubah kata/kalimat menjadi bilangan bilangan.\\nproses mengubah kata menjadi bilangan bilangan disebut sebagai tokenization\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#import tokenizer\r\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#tokenizer berfungsi untuk mengubah kata menjadi bilangna tertentu\r\n",
    "# bisa dilakukan dengan menggunakan keras Tokenizer\r\n",
    "# pada instansiasi di bawah digunakan parameter num_words, digunakan untuk membatasi berapa kata paling frequent yang akan ditokenisasi\r\n",
    "# sedangkan oov_token berfungsi untuk mengganti kata yang tidak ditokenisasi, berguna untuk tetap menjaga inforamsi suatu kalimat.\r\n",
    "tokenizer =Tokenizer(num_words=15, oov_token='-')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "teks = ['Saya suka programming',\r\n",
    "        'Programming sangat menyenangkan!',\r\n",
    "        'Machine Learning berbeda dengan pemrograman konvensional']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#mengaplikasikan tokenisasi ke teks/mengubah kata menjadi bilangan tertentu\r\n",
    "tokenizer.fit_on_texts(teks)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# mengubah kalimat menjadi array dari kata yang sudah ditokenisasi\r\n",
    "sequences = tokenizer.texts_to_sequences(teks)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# hasil tokenisasi kata\r\n",
    "#tanda baca dan huruf kapital tidak diperhatikan, sehingga kata sama dengan huruf kapital/tanda baca berbeda dianggap sama\r\n",
    "print(tokenizer.word_index)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'-': 1, 'programming': 2, 'saya': 3, 'suka': 4, 'sangat': 5, 'menyenangkan': 6, 'machine': 7, 'learning': 8, 'berbeda': 9, 'dengan': 10, 'pemrograman': 11, 'konvensional': 12}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# selanjutnya yaitu padding, padding merupakan proses menyamakan panjang sequences, pada contoh 'teks',\r\n",
    "# kalimat yang kita miliki tidak sama panjang, seperti halnya dalam pemrosesan gambar, kita perlu menyamakan ukuran gambar\r\n",
    "# pada teks, kita menggunakan padding. kata yang lebih pendek dari panjang yang ditentukan, akan ditempel angka 0 di sequence nya\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "# maxlen merupakan panjang maksimal suatu kata\r\n",
    "# jika kata melebihi panjang maxlen, maka akan dipotong,\r\n",
    "# parameter padding menentukan di mana angka 0 akan ditambahkan pada sequence, defaultnya di depan kalimat,\r\n",
    "# jika padding diberi nilai 'post', maka 0 akan ditambahkan di belakang kalimat.\r\n",
    "# truncating berfungsi untuk menentukan, bagian mana yang akan dipotong jika suatu sequence melebihi panjang yang ditentukan\r\n",
    "# jika tidak ditentukan, bagian depan kalimat akan dipotong. jika diberi nilai 'post', bagian belakang akan dipotong\r\n",
    "sequences_samapanjang = pad_sequences(sequences, padding='post', maxlen=5, truncating='post')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "sequences_samapanjang"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 3,  4,  2,  0,  0],\n",
       "       [ 2,  5,  6,  0,  0],\n",
       "       [ 7,  8,  9, 10, 11]])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit"
  },
  "interpreter": {
   "hash": "965ba1120b0c101b3f715b6e258a73742ec1cf86f2c8b04492724c87d9f112c3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}